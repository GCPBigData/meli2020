{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import joblib\n",
    "\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "import glob\n",
    "\n",
    "import numba\n",
    "import dask\n",
    "import xgboost\n",
    "from dask.diagnostics import ProgressBar\n",
    "import re\n",
    "ProgressBar().register()\n",
    "fold1, fold2 = joblib.load(\"./valid/fold1.pkl.z\"), joblib.load(\"./valid/fold2.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"./data/train.parquet\")\n",
    "train_melt = pd.read_parquet(\"./data/22c_train_melt_with_features.parquet\")\n",
    "test_melt = pd.read_parquet(\"./data/22c_test_melt_with_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = pd.read_parquet(\"./data/item_data.parquet\")\n",
    "item_data.head()\n",
    "\n",
    "item_title_map = item_data[['item_id', 'title']].drop_duplicates()\n",
    "item_title_map = item_title_map.set_index(\"item_id\").squeeze().to_dict()\n",
    "\n",
    "item_price_map = item_data[['item_id', 'price']].drop_duplicates()\n",
    "item_price_map = item_price_map.set_index(\"item_id\").squeeze().to_dict()\n",
    "\n",
    "item_domain_map = item_data[['item_id', 'domain_id']].drop_duplicates()\n",
    "item_domain_map = item_domain_map.set_index(\"item_id\").squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stack gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_pos = np.log1p(np.arange(1,11))\n",
    "best_sellers = [1587422, 1803710,   10243,  548905, 1906937,  716822, 1361154, 1716388,  725371,  859574]\n",
    "best_sellers_domain = [item_domain_map[e] for e in best_sellers]\n",
    "\n",
    "def pad(lst):\n",
    "    \n",
    "    if len(lst) == 0:\n",
    "        return best_sellers\n",
    "    if len(lst) < 10:\n",
    "        lst += best_sellers[:(10 - len(lst))]\n",
    "    return np.array(lst)\n",
    "\n",
    "def pad_str(lst):\n",
    "    if len(lst) == 0:\n",
    "        return best_sellers_domain\n",
    "    if len(lst) < 10:\n",
    "        lst += best_sellers_domain[:(10 - len(lst))]\n",
    "    return lst\n",
    "\n",
    "# this is wrong, double counts exact item hits\n",
    "def ndcg_vec(ytrue, ypred, ytrue_domain, ypred_domain):\n",
    "    relevance = np.zeros((ypred.shape[0], 10))\n",
    "    for i in range(10):\n",
    "        relevance[:, i] = np.equal(ypred_domain[:, i], ytrue_domain) * (np.equal(ypred[:, i], ytrue) * 12 + 1)\n",
    "    dcg = (relevance / log_pos).sum(axis=1)\n",
    "\n",
    "    i_relevance = np.ones(10)\n",
    "    i_relevance[0] = 12.\n",
    "    idcg = np.zeros(ypred.shape[0]) + (i_relevance / log_pos).sum()\n",
    "\n",
    "    return (dcg / idcg).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tr_list = glob.glob(\"./stack_2f/*_train.parquet\")\n",
    "ts_list = glob.glob(\"./stack_2f/*_test.parquet\")\n",
    "\n",
    "train = train_melt[['seq_index','event_info','has_bought', 'item_domain', 'bought_domain', 'bought_id', 'y_rank']].copy()\n",
    "for f in tr_list:\n",
    "    fname = re.search('/(\\d[\\d\\w]+)_', f).group(1)\n",
    "    fdf = pd.read_parquet(f).rename(columns={\"p\": fname})\n",
    "    train = pd.merge(train, fdf, on=['seq_index','event_info'])\n",
    "    \n",
    "train = train.sort_values(\"seq_index\")\n",
    "    \n",
    "test = test_melt[['seq_index','event_info']].copy()\n",
    "for f in ts_list:\n",
    "    fname = re.search('/(\\d[\\d\\w]+)_', f).group(1)\n",
    "    fdf = pd.read_parquet(f).rename(columns={\"p\": fname})\n",
    "    test = pd.merge(test, fdf, on=['seq_index','event_info'])\n",
    "    \n",
    "test = test.sort_values(\"seq_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from cuml.preprocessing import TargetEncoder\n",
    "\n",
    "\n",
    "stack_p = list()\n",
    "for f1, f2 in [(fold1, fold2), (fold2, fold1)]:\n",
    "    Xtr = train[train['seq_index'].isin(f1)]\n",
    "    Xval = train[train['seq_index'].isin(f2)]\n",
    "\n",
    "\n",
    "    features = ['22c', '26']\n",
    "\n",
    "    params = [0.1, 3, 1, 0.5, 1.]\n",
    "    learning_rate, max_depth, min_child_weight, subsample, colsample_bytree = params\n",
    "\n",
    "\n",
    "    Xtrr, ytr = Xtr[features], Xtr['y_rank']\n",
    "    Xvall = Xval[features]\n",
    "    \n",
    "    groups = Xtr.groupby('seq_index').size().values\n",
    "\n",
    "    mdl = xgboost.XGBRanker(seed=0, tree_method='gpu_hist', gpu_id=0, n_estimators=100,\n",
    "                               learning_rate=learning_rate, max_depth=max_depth, min_child_weight=min_child_weight,\n",
    "                                subsample=subsample, colsample_bytree=colsample_bytree, objective='rank:pairwise', num_parallel_tree=5)\n",
    "\n",
    "    mdl.fit(Xtrr, ytr, group=groups)\n",
    "\n",
    "    p = mdl.predict(Xvall)\n",
    "\n",
    "    preds = Xval[['seq_index', 'has_bought', 'item_domain', 'bought_domain', 'event_info', 'bought_id']].copy()\n",
    "    preds['p'] = p\n",
    "    \n",
    "    preds = preds.sort_values('p', ascending=False).drop_duplicates(subset=['seq_index', 'event_info'])\n",
    "\n",
    "    ytrue = preds.groupby(\"seq_index\")['bought_id'].apply(lambda x: x.iloc[0]).values\n",
    "    ytrue_domain = preds.groupby(\"seq_index\")['bought_domain'].apply(lambda x: x.iloc[0]).values\n",
    "\n",
    "    ypred = preds.groupby(\"seq_index\")['event_info'].apply(lambda x: pad(x.iloc[:10].tolist()))\n",
    "    ypred = np.array(ypred.tolist())\n",
    "\n",
    "    ypred_domain = preds.groupby(\"seq_index\")['item_domain'].apply(lambda x: pad_str(x.iloc[:10].tolist()))\n",
    "    ypred_domain = np.array(ypred_domain.tolist())\n",
    "\n",
    "    print(ndcg_vec(ytrue, ypred, ytrue_domain, ypred_domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train.groupby('seq_index').size().values\n",
    "learning_rate, max_depth, min_child_weight, subsample, colsample_bytree = params\n",
    "mdl = xgboost.XGBRanker(seed=0, tree_method='gpu_hist', gpu_id=0, n_estimators=100,\n",
    "                           learning_rate=learning_rate, max_depth=max_depth, min_child_weight=min_child_weight,\n",
    "                            subsample=subsample, colsample_bytree=colsample_bytree, objective='rank:pairwise', num_parallel_tree=5)\n",
    "mdl.fit(train[features], train['y_rank'], group=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test[['seq_index', 'event_info']].copy()\n",
    "preds['p'] = p\n",
    "preds = preds.sort_values('p', ascending=False).drop_duplicates(subset=['seq_index', 'event_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(lst):\n",
    "    pad_candidates = [1587422, 1803710,   10243,  548905, 1906937,  716822, 1361154, 1716388,  725371,  859574]\n",
    "    if len(lst) == 0:\n",
    "        return pad_candidates\n",
    "    if len(lst) < 10:\n",
    "        lst += [lst[0]] * (10 - len(lst)) # pad_candidates[:(10 - len(lst))]\n",
    "    return np.array(lst)\n",
    "ypred = preds.groupby(\"seq_index\")['event_info'].apply(lambda x: pad(x.iloc[:10].tolist()))\n",
    "seq_index = ypred.index\n",
    "ypred = np.array(ypred.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_final = np.zeros((177070, 10))\n",
    "ypred_final[seq_index, :] = ypred\n",
    "no_views = np.setdiff1d(np.arange(177070), seq_index)\n",
    "#ypred_final[no_views, :] = np.array([1587422, 1803710,   10243,  548905, 1906937,  716822, 1361154, 1716388,  725371,  859574])\n",
    "ypred_final = ypred_final.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permite produtos repetidos\n",
    "pd.DataFrame(ypred_final).to_csv(\"./subs/27.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['seq_index'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l ./subs/27.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ./subs/27.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
